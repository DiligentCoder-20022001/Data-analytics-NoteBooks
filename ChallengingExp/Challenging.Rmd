---
title: "Challenging experiment"
author: "Siddharth.S.Chandran (18BCE1003) and Shubham Agarwal(18BCE1184)"
date: "23/03/2021"
output:
  pdf_document: default
  html_document: default
---

1. Reading the dataset 
```{r}
library(readxl)
dat<-read_excel("C:/Users/Siddharth.S.Chandran/Desktop/MyProjects/DataAnalytics/challenging.xlsx")
str(dat)
summary(dat)
```

Normalizing the values 

Before normalization 

```{r}
boxplot(dat)
```

We can see that the values are higly differing. We therefore have to perform normalization, We apply the standardization technique 

```{r}
library(caret)
preproc1 <- preProcess(dat, method=c("center", "scale"))
norm1 <- predict(preproc1, dat)
summary(norm1)
boxplot(norm1)
```

After the standardization process we can see that each and every variable has not much differences in  their values, and is hencce normalizaed 

2. Stage1 (inputs -> x1, x2, x3 and outputs -> y1, y2)

a. Correlation between the input variables 

```{r}
data1<-norm1[,c(2,3,4)]
cor(data1)
```

The input variables have 0 correlation between them 

b. 
```{r}
data1<-norm1[,c(2,3,4,5,6)]
cor(data1)
```
c. Y1 and X1 have the strongest correlation of -0.9 
   Y2 and X3 follows that with a correlation of 0.66 

d. Graphical inferences

```{r}
plot(norm1$Y1, norm1$X1)
plot(norm1$Y2, norm1$X3)
```
3. Stage2 classifier (y2 input and z1 output )
a. Correlation between input variables

```{r}
data1<-norm1[,c(5,6)]
cor(data1)
```

The input variables have a good amount of correlation of -0.5

b. Correlation between input and output variables

```{r}
data1<-norm1[,c(5,6,7)]
cor(data1)
```
c. Z1 and Y1 have the strongest correlation of -0.92. 
   Z1 and Y2 have a good correlation of 0.5 

d. Graphical inference 
```{r}
plot(norm1$Z1, norm1$Y1)
plot(norm1$Z1, norm1$Y2)
```

4. Applying suitable regression techniques 

a. Linear regression 

Scaling the data 
Dividing it into testing and training 
```{r}
set.seed(100) 

index = sample(1:nrow(dat), 0.7*nrow(dat)) 

train = dat[index,] # Create the training data 
test = dat[-index,] # Create the test data

dim(train)
dim(test)
pre_proc_val <- preProcess(train, method = c("center", "scale"))

train = predict(pre_proc_val, train)
test = predict(pre_proc_val, test)

summary(train)
```
```{r}
cols = c('Y1', 'X1','X2', 'X3')

pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))

train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])

summary(train)
```
```{r}
lr1 = lm(Y1 ~ X1 + X2 + X3, data = train)
summary(lr1)
lr1
lr2 = lm(Y2 ~ X1 + X2 + X3, data = train)
summary(lr2)
lr2
```
```{r}
#Step 1 - create the evaluation metrics function

eval_metrics = function(model, df, predictions, target){
    resids = df[,target] - predictions
    resids2 = resids**2
    N = length(predictions)
    r2 = as.character(round(summary(model)$r.squared, 2))
    adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
    print(adj_r2) #Adjusted R-squared
    print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}

# Step 2 - predicting and evaluating the model on train data
predictions = predict(lr1, newdata = train)
eval_metrics(lr1, train, predictions, target = 'Y1')

# Step 3 - predicting and evaluating the model on test data
predictions = predict(lr1, newdata = test)
eval_metrics(lr1, test, predictions, target = 'Y1')
d<-predictions - test[,c('Y1')]

mse = mean((d[,c('Y1')])^2)
mse
mae = mean(abs(d[,c('Y1')]))
mae
```

Stage 1 classifier on y1 (linear regression)

RMSE -> 0.92 
R squared -> 0.27
MSE -> 0.077
MAE -> 0.26

```{r}
#Step 1 - create the evaluation metrics function

eval_metrics = function(model, df, predictions, target){
    resids = df[,target] - predictions
    resids2 = resids**2
    N = length(predictions)
    r2 = as.character(round(summary(model)$r.squared, 2))
    adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
    print(adj_r2) #Adjusted R-squared
    print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}

# Step 2 - predicting and evaluating the model on train data
predictions = predict(lr2, newdata = train)
eval_metrics(lr1, train, predictions, target = 'Y2')

# Step 3 - predicting and evaluating the model on test data
predictions = predict(lr2, newdata = test)
eval_metrics(lr2, test, predictions, target = 'Y2')
d<-predictions - test[,c('Y2')]

mse = mean((d[,c('Y2')])^2)
mse
mae = mean(abs(d[,c('Y2')]))
mae
```
The values for Stage 1 classifier on y2 (linear regression are) 
1. RMSE -> 0.68 
2. R sqaured -> 0.44 
3. MSE -> 0.197
4. MAE -> 0.34

Stage 2 classifier 
```{r}
cols = c('Y1', 'Y2', 'Z1')

pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))

train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])

summary(train)
```
```{r}
lr = lm(Z1 ~ Y1 + Y2, data = train)
lr
summary(lr)
```
```{r}
#Step 1 - create the evaluation metrics function

eval_metrics = function(model, df, predictions, target){
    resids = df[,target] - predictions
    resids2 = resids**2
    N = length(predictions)
    r2 = as.character(round(summary(model)$r.squared, 2))
    adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
    print(adj_r2) #Adjusted R-squared
    print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}

# Step 2 - predicting and evaluating the model on train data
predictions = predict(lr, newdata = train)
eval_metrics(lr, train, predictions, target = 'Z1')

# Step 3 - predicting and evaluating the model on test data
predictions = predict(lr, newdata = test)
eval_metrics(lr, test, predictions, target = 'Z1')
d<-predictions - test[,c('Z1')]

mse = mean((d[,c('Z1')])^2)
mse
mae = mean(abs(d[,c('Z1')]))
mae
```
The values for stage 2 classifier on linear regression are 
1. RMSE -> 0.87
2. R squared -> 0.46
3. MSE -> 0.211
4. MAE -> 0.33

b. Ridge regression 

Dividing the data into training and testing 
```{r}
set.seed(100) 

index = sample(1:nrow(dat), 0.7*nrow(dat)) 

train = dat[index,] # Create the training data 
test = dat[-index,] # Create the test data

dim(train)
dim(test)
```

Scaling the data
```{r}
pre_proc_val <- preProcess(train, method = c("center", "scale"))

train = predict(pre_proc_val, train)
test = predict(pre_proc_val, test)

summary(train)
```

Regularization 

Linear regression works with independent variables which minimizes the loss function, however if the data values are large enough it leads to overfitting of the data and such a model cannot be used for generalization 

```{r}

dummies <- dummyVars(Y1 ~ ., data = dat[,c(1:5)])

train_dummies = predict(dummies, newdata = train[,c(1:5)])

test_dummies = predict(dummies, newdata = test[,c(1:5)])

print(dim(train_dummies)); print(dim(test_dummies))
```

Applying ridge regression on stage 1 classifier
```{r}
library(glmnet)

x = as.matrix(train_dummies)
y_train = train$Y1

x_test = as.matrix(test_dummies)
y_test = test$Y1

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = lambdas)

summary(ridge_reg)
```

This code runs for several values of lambda. Let us find the optimal lambda 

```{r}
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
```

The optimal lambda comes to be 0.025

Evaluating the model results based on the lambda value 
```{r}
# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquare = R_square
)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
eval_results(y_train, predictions_train, train)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
eval_results(y_test, predictions_test, test)
d<-predictions_test - test[,c('Y1')]

mse = mean((d[,c('Y1')])^2)
mse
mae = mean(abs(d[,c('Y1')]))
mae
```

For testing dataset in stage 1 classifier using ridge regression the vaules are 

1. RMSE -> 0.2777
2. R squared -> 0.884
3. MSE -> 0.077
4. MAE -> 0.259


Stage 1 classifier for Y2
generalization 

```{r}

dummies <- dummyVars(Y2 ~ ., data = dat[,c('X1', 'X2', 'X3', 'Y2')])

train_dummies = predict(dummies, newdata = train[,c('X1', 'X2', 'X3', 'Y2')])

test_dummies = predict(dummies, newdata = test[,c('X1', 'X2', 'X3', 'Y2')])

print(dim(train_dummies)); print(dim(test_dummies))
```

Applying ridge regression on stage 1 classifier
```{r}
library(glmnet)

x = as.matrix(train_dummies)
y_train = train$Y2

x_test = as.matrix(test_dummies)
y_test = test$Y2

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = lambdas)

summary(ridge_reg)
```       

This code runs for several values of lambda. Let us find the optimal lambda 

```{r}
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
```

The optimal lambda comes to be 0.039

Evaluating the model results based on the lambda value 
```{r}
# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquare = R_square
)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
eval_results(y_train, predictions_train, train)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
eval_results(y_test, predictions_test, test)
d<-predictions_test - test[,c('Y2')]
d
mse = mean((d[,c('Y2')])^2)
mse
mae = mean(abs(d[,c('Y2')]))
mae
```
The values for stage 1 classifier on y2 are (ridge regression)
RMSE -> 0.45
R squared -> 0.77 
MSE -> 0.202
MAE -> 0.35

Stage 2 classifier 
```{r}
cols_reg = c('Y2', 'Z1', 'Y1')
dummies <- dummyVars(Z1 ~ ., data = dat[,cols_reg])

train_dummies = predict(dummies, newdata = train[,cols_reg])

test_dummies = predict(dummies, newdata = test[,cols_reg])

print(dim(train_dummies)); print(dim(test_dummies))
```
```{r}
library(glmnet)

x = as.matrix(train_dummies)
y_train = train$Z1

x_test = as.matrix(test_dummies)
y_test = test$Z1

lambdas <- 10^seq(2, -3, by = -.1)
ridge_reg = glmnet(x, y_train, nlambda = 25, alpha = 0, family = 'gaussian', lambda = lambdas)

summary(ridge_reg)
```
```{r}
cv_ridge <- cv.glmnet(x, y_train, alpha = 0, lambda = lambdas)
optimal_lambda <- cv_ridge$lambda.min
optimal_lambda
```

```{r}
# Compute R^2 from true and predicted values
eval_results <- function(true, predicted, df) {
  SSE <- sum((predicted - true)^2)
  SST <- sum((true - mean(true))^2)
  R_square <- 1 - SSE / SST
  RMSE = sqrt(SSE/nrow(df))

  
  # Model performance metrics
data.frame(
  RMSE = RMSE,
  Rsquare = R_square
)
  
}

# Prediction and evaluation on train data
predictions_train <- predict(ridge_reg, s = optimal_lambda, newx = x)
eval_results(y_train, predictions_train, train)

# Prediction and evaluation on test data
predictions_test <- predict(ridge_reg, s = optimal_lambda, newx = x_test)
eval_results(y_test, predictions_test, test)
d<-predictions_test - test[,c('Z1')]
d
mse = mean((d[,c('Z1')])^2)
mse
mae = mean(abs(d[,c('Z1')]))
mae
```
The values for stage 2 classifier on ridge regression are 

1. RMSE -> 0.46
2. R squared -> 0.76
3. MSE ->0.212
4. MAE -> 0.33


Same applies for Stage 2 too. The linear model is found to be better. 

b. Lasso regression 

For stage 1 classifier (for Y1) 

```{r}
cols = c('X1','X2','X3','Y1')

pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))

train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])

summary(train)
```

```{r}
cols_reg = c(1:5)

dummies <- dummyVars(Y1 ~ ., data = dat[,cols_reg])

train_dummies = predict(dummies, newdata = train[,cols_reg])

test_dummies = predict(dummies, newdata = test[,cols_reg])

print(dim(train_dummies)); print(dim(test_dummies))
```

Finding the optimal lamba value for lasso regression 

```{r}
lambdas <- 10^seq(2, -3, by = -.1)

# Setting alpha = 1 implements lasso regression
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 5)

# Best 
lambda_best <- lasso_reg$lambda.min 
lambda_best
```

Now we train the lasso model using the obtained lambda values 
```{r}
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
eval_results(y_train, predictions_train, train)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
eval_results(y_test, predictions_test, test)
d<-predictions_test - test[,c('Y1')]
d
mse = mean((d[,c('Y1')])^2)
mse
mae = mean(abs(d[,c('Y1')]))
mae
```
The values for stage 1 classifier (on Y1) using Lasso regression are 

1. RMSE -> 0.46
2. R square -> 0.76
3. MSE -> 2.67
4. MAE -> 1.34


The model shows decreased R square value for testing and increased RMSE for testing which indicates that this model is also not good enough 

Stage 1 classifier for Y2

```{r}
cols = c('X1','X2','X3','Y2')

pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))

train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])

summary(train)
```

```{r}
cols_reg = c(1:5)

dummies <- dummyVars(Y1 ~ ., data = dat[,cols_reg])

train_dummies = predict(dummies, newdata = train[,cols_reg])

test_dummies = predict(dummies, newdata = test[,cols_reg])

print(dim(train_dummies)); print(dim(test_dummies))
```

Finding the optimal lamba value for lasso regression 

```{r}
lambdas <- 10^seq(2, -3, by = -.1)

# Setting alpha = 1 implements lasso regression
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 5)

# Best 
lambda_best <- lasso_reg$lambda.min 
lambda_best
```

Now we train the lasso model using the obtained lambda values 
```{r}
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
eval_results(y_train, predictions_train, train)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
eval_results(y_test, predictions_test, test)
d<-predictions_test - test[,c('Y2')]
d
mse = mean((d[,c('Y2')])^2)
mse
mae = mean(abs(d[,c('Y2')]))
mae
```
Values of stage1 classifier on Y2 using lasso regression are 
1. RMSE -> 0.46
2. R square -> 0.76
3. MSE -> 0.63
4. MAE -> 0.64

b. Stage 2 classifier
```{r}
cols = c('Y1','Y2','Z1')

pre_proc_val <- preProcess(train[,cols], method = c("center", "scale"))

train[,cols] = predict(pre_proc_val, train[,cols])
test[,cols] = predict(pre_proc_val, test[,cols])

summary(train)
```

```{r}
cols_reg = c('Y1','Y2','Z1')

dummies <- dummyVars(Z1 ~ ., data = dat[,cols_reg])

train_dummies = predict(dummies, newdata = train[,cols_reg])

test_dummies = predict(dummies, newdata = test[,cols_reg])

print(dim(train_dummies)); print(dim(test_dummies))
```

Finding the optimal lambda value for lasso regression 

```{r}
lambdas <- 10^seq(2, -3, by = -.1)

# Setting alpha = 1 implements lasso regression
lasso_reg <- cv.glmnet(x, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 5)

# Best 
lambda_best <- lasso_reg$lambda.min 
lambda_best
```


Now we train the lasso model using the obtained lambda values 
```{r}
lasso_model <- glmnet(x, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)

predictions_train <- predict(lasso_model, s = lambda_best, newx = x)
eval_results(y_train, predictions_train, train)

predictions_test <- predict(lasso_model, s = lambda_best, newx = x_test)
eval_results(y_test, predictions_test, test)
d<-predictions_test - test[,c('Z1')]
d
mse = mean((d[,c('Z1')])^2)
mse
mae = mean(abs(d[,c('Z1')]))
mae
```
The values for stage 2 classifier using Lasso regression are 
1. RMSE -> 0.46
2. R sqaure -> 0.76
3. MSE -> 0.21
4. MAE -> 0.34

Shows the same and hence is again not a good model 


8. Plotting 

Linear regression model will be a better model 
```{r}
model1<-lm(Y1~X1+X2+X3, data = train)
plot(model1)
model2<-lm(Y2~X1+X2+X3, data = train)
plot(model2)
model3<-lm(Z1~Y1+Y2, data=train)
plot(model3)
```

From the graphs we can say that linear graph suits well.